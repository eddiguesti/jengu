# COMPREHENSIVE CODE AUDIT REPORT

## Jengu Travel Pricing Platform

**Audit Date:** October 15, 2025
**Auditor:** Claude Code Agent
**Code Health Score:** 6.5/10

---

## EXECUTIVE SUMMARY

Your application has a **solid architectural foundation** with good separation of concerns, modern technology stack, and comprehensive feature set. However, there are **critical security vulnerabilities** and missing error handling that must be addressed before production deployment.

### Key Findings:

- âœ… **Strengths:** Well-organized services, modern stack, feature-rich
- âš ï¸ **Critical Issues:** 1 exposed API key, incomplete error handling, broken holiday enrichment
- ðŸ“Š **Code Quality:** Generally good but needs refactoring to reduce duplication
- ðŸ”’ **Security:** One critical vulnerability, otherwise acceptable
- ðŸ§ª **Testing:** No test coverage (major gap)

---

## 1. CRITICAL ISSUES (P0 - FIX IMMEDIATELY)

### ðŸ”´ 1.1 SECURITY: Exposed API Key in Frontend

**File:** `frontend/src/lib/api/services/weather.ts:11`

```typescript
const OPENWEATHER_API_KEY = 'ad75235deeaa288b6389465006fad960'
```

**Risk Level:** CRITICAL
**Impact:**

- API key visible in browser developer tools
- Anyone can extract and abuse your key
- Potential billing fraud
- API rate limits could be exhausted by attackers

**Solution:**

```typescript
// REMOVE the hardcoded key
// Option 1: Use backend proxy endpoint (RECOMMENDED)
export async function getCurrentWeather(lat: number, lon: number) {
  return apiClient.get('/api/weather/current', {
    params: { latitude: lat, longitude: lon },
  })
}

// Option 2: If you must use frontend, use environment variable
const API_KEY = import.meta.env.VITE_OPENWEATHER_API_KEY // NOT RECOMMENDED
```

**Action Required:** Delete this key from OpenWeather dashboard and generate a new one after fixing the code.

---

### ðŸ”´ 1.2 Broken Feature: Holiday Enrichment

**File:** `backend/services/enrichmentService.js:186-248`

**Issue:** Code references `prisma` (old ORM) but system uses Supabase now.

```javascript
export async function enrichWithHolidays(propertyId, countryCode, calendarificApiKey, prisma) {
  // âŒ This entire function is broken - uses removed Prisma ORM
  const pricingData = await prisma.pricingData.findMany({
    /* ... */
  })
}
```

**Impact:** Holiday enrichment silently fails, users don't get holiday pricing insights

**Solution:**

```javascript
// Option 1: Migrate to Supabase (RECOMMENDED)
export async function enrichWithHolidays(
  propertyId,
  countryCode,
  calendarificApiKey,
  supabaseClient
) {
  const { data: pricingData } = await supabaseClient
    .from('pricing_data')
    .select('id, date')
    .eq('propertyId', propertyId)
  // ... rest of logic
}

// Option 2: Remove feature until ready to implement
// Comment out or delete the function
```

---

### ðŸ”´ 1.3 Function Shadowing (Confusing/Buggy)

**File:** `backend/server.js:173-185`

```javascript
// âŒ BAD: Shadows JavaScript global functions
const parseFloat = val => {
  /* custom logic */
}
const parseInt = val => {
  /* custom logic */
}
```

**Issue:**

- Extremely confusing for developers
- Can cause subtle bugs when refactoring
- Best practices violation

**Solution:**

```javascript
// âœ… GOOD: Rename to avoid shadowing
const parseFloatSafe = val => {
  if (val === null || val === undefined || val === '') return null
  const num = Number(val)
  return isNaN(num) ? null : num
}

const parseIntSafe = val => {
  if (val === null || val === undefined || val === '') return null
  const num = Number(val)
  return isNaN(num) ? null : Math.floor(num)
}
```

---

### ðŸ”´ 1.4 Missing Error Recovery in Batch Inserts

**File:** `backend/server.js:250-266`

**Current Code:**

```javascript
const { error: batchError } = await supabaseAdmin.from('pricing_data').insert(batchData)

if (batchError) {
  console.error('Batch insert error:', batchError) // âŒ Only logs
} else {
  console.log(`âœ… Inserted batch...`)
}
// âŒ Upload continues even if batch fails - results in incomplete data!
```

**Problem:** If batch 2 of 4 fails, batches 3 and 4 still insert â†’ inconsistent database state

**Solution:**

```javascript
try {
  const { error: batchError } = await supabaseAdmin.from('pricing_data').insert(batchData)

  if (batchError) {
    // Abort entire upload, rollback property record
    await supabaseAdmin.from('properties').delete().eq('id', property.id)

    throw new Error(`Batch insert failed: ${batchError.message}`)
  }

  console.log(`âœ… Inserted batch ${batchNum}...`)
} catch (error) {
  // Clean up file, return error to user
  fs.unlinkSync(filePath)
  throw error
}
```

---

### ðŸ”´ 1.5 No Request Timeouts

**All axios calls lack timeout configuration:**

```javascript
// âŒ BAD: No timeout - hangs forever if API is slow
const response = await axios.get('https://archive-api.open-meteo.com/v1/archive', {
  params: {
    /* ... */
  },
})

// âœ… GOOD: Add timeout
const response = await axios.get('https://archive-api.open-meteo.com/v1/archive', {
  params: {
    /* ... */
  },
  timeout: 30000, // 30 seconds
  retry: 3, // Retry 3 times on failure
})
```

**Impact:** Server can hang indefinitely waiting for external APIs

---

## 2. HIGH PRIORITY ISSUES (P1 - FIX THIS SPRINT)

### 2.1 CSV Validation Missing

**File:** `backend/server.js:119-382`

**Issue:** No validation of CSV structure before processing

**Risks:**

- Malicious CSV files (code injection)
- Malformed data causing crashes
- Memory exhaustion from huge files
- Infinite loop from circular references

**Add Validation:**

```javascript
// After parsing headers
if (columnCount > 100) {
  throw new Error('Too many columns (max 100)')
}

if (totalRows > 100000) {
  throw new Error('Too many rows (max 100,000)')
}

// Validate required columns
const requiredColumns = ['date', 'price']
const missingColumns = requiredColumns.filter(col => !headers.includes(col))
if (missingColumns.length > 0) {
  throw new Error(`Missing required columns: ${missingColumns.join(', ')}`)
}
```

---

### 2.2 Race Conditions in React Components

**File:** `frontend/src/pages/Insights.tsx:226-246`

**Issue:** Multiple `useEffect` hooks modifying same state without coordination

```typescript
// Hook 1: Updates when fileId changes
useEffect(() => {
  loadUploadedData()
}, [fileId])

// Hook 2: Updates when uploadedFiles changes
useEffect(() => {
  const file = uploadedFiles.find(f => f.id === currentFileId)
  setInsights(/* ... */)
}, [uploadedFiles])

// Hook 3: Generates insights when data changes
useEffect(() => {
  generateInsights()
}, [data])
```

**Problem:** All 3 can trigger simultaneously â†’ race condition â†’ stale data

**Solution:**

```typescript
// Combine into single coordinated effect
useEffect(() => {
  let cancelled = false

  async function loadAndGenerate() {
    const data = await loadUploadedData()
    if (cancelled) return

    const insights = await generateInsights(data)
    if (cancelled) return

    setInsights(insights)
  }

  loadAndGenerate()

  return () => {
    cancelled = true
  }
}, [fileId, uploadedFiles])
```

---

### 2.3 Memory Leak: Missing Cleanup

**File:** `frontend/src/pages/Data.tsx:422`

**Issue:**

```typescript
// âŒ setInterval never cleared
setInterval(() => {
  checkEnrichmentStatus()
}, 5000)
```

**Fix:**

```typescript
useEffect(() => {
  const interval = setInterval(() => {
    checkEnrichmentStatus()
  }, 5000)

  return () => clearInterval(interval) // âœ… Cleanup
}, [])
```

---

### 2.4 Inconsistent Error Responses

**Backend has 3 different error formats:**

```javascript
// Format 1:
res.status(500).json({
  error: 'Failed to upload file',
  message: error.message,
})

// Format 2:
res.status(400).json({
  error: 'Missing required fields: cityId',
})

// Format 3:
res.status(404).json({
  error: 'File not found',
}) // No message field
```

**Standardize:**

```javascript
// âœ… Consistent format
class ApiError {
  constructor(status, code, message, details = null) {
    this.status = status
    this.error = {
      code,
      message,
      details,
      timestamp: new Date().toISOString(),
    }
  }
}

// Usage:
throw new ApiError(400, 'VALIDATION_ERROR', 'Missing required field', { field: 'cityId' })
```

---

## 3. CODE DUPLICATION (P2 - REFACTOR)

### 3.1 Date Parsing (Duplicated 3x)

**Locations:**

- `backend/server.js:163-171`
- `backend/services/dataTransform.js:81-91`
- Multiple frontend components

**Create Shared Utility:**

```javascript
// backend/utils/dateParser.js
export function parseDate(dateStr) {
  if (!dateStr) return null

  try {
    const date = new Date(dateStr)
    return isNaN(date.getTime()) ? null : date
  } catch {
    return null
  }
}

// Then import and use everywhere:
import { parseDate } from '../utils/dateParser.js'
```

---

### 3.2 Weather Code Mapping (Duplicated 2x)

**Locations:**

- `backend/server.js:626-637`
- `backend/services/enrichmentService.js:58-67`

**Extract to Constant:**

```javascript
// backend/constants/weather.js
export const WEATHER_CODE_MAP = {
  0: 'Clear',
  1: 'Partly Cloudy',
  2: 'Partly Cloudy',
  3: 'Partly Cloudy',
  45: 'Foggy',
  48: 'Foggy',
  // ... etc
}

export function getWeatherDescription(code) {
  return WEATHER_CODE_MAP[code] || 'Unknown'
}
```

---

### 3.3 Column Name Mapping (Duplicated)

**Both `server.js` and `dataTransform.js` do the same field mapping**

**Consolidate:**

```javascript
// Use dataTransform service on backend too
import { transformDataForAnalytics } from './services/dataTransform.js'

// In upload handler:
const transformedData = transformDataForAnalytics(allRows)
```

---

## 4. PERFORMANCE OPTIMIZATIONS (P2)

### 4.1 Large File Upload Memory Issue

**File:** `backend/server.js:187-207`

**Current:**

```javascript
const allRows = [];
await new Promise((resolve, reject) => {
  fs.createReadStream(filePath)
    .pipe(csv())
    .on('data', (row) => {
      allRows.push(row); // âŒ Stores ALL rows in memory
    })
```

**Problem:** 50MB CSV with 1M rows = ~500MB RAM usage

**Streaming Solution:**

```javascript
let currentBatch = []
const BATCH_SIZE = 1000

await new Promise((resolve, reject) => {
  fs.createReadStream(filePath)
    .pipe(csv())
    .on('data', async row => {
      currentBatch.push(row)

      if (currentBatch.length >= BATCH_SIZE) {
        stream.pause() // Pause while inserting
        await insertBatch(currentBatch)
        currentBatch = []
        stream.resume() // Resume reading
      }
    })
    .on('end', async () => {
      if (currentBatch.length > 0) {
        await insertBatch(currentBatch)
      }
      resolve()
    })
})
```

---

### 4.2 Frontend Data Caching

**File:** `frontend/src/pages/Insights.tsx:103`

**Issue:**

```typescript
// âŒ Re-fetches 10,000 rows on EVERY component mount
const response = await axios.get(`http://localhost:3001/api/files/${fileId}/data?limit=10000`)
```

**Solution with React Query:**

```typescript
import { useQuery } from '@tanstack/react-query'

const { data, isLoading } = useQuery({
  queryKey: ['fileData', fileId],
  queryFn: () => fetchFileData(fileId),
  staleTime: 5 * 60 * 1000, // Cache for 5 minutes
  cacheTime: 10 * 60 * 1000, // Keep in cache for 10 minutes
})
```

**Benefits:**

- Automatic caching
- Background refetching
- Loading/error states
- Deduplication

---

### 4.3 Component Code Splitting

**Large components should be split:**

- `Data.tsx` (955 lines) â†’ Split into:
  - `FileUpload.tsx`
  - `FileList.tsx`
  - `EnrichmentPanel.tsx`

- `Insights.tsx` (639 lines) â†’ Split into:
  - `InsightsCharts.tsx`
  - `AnalyticsSummary.tsx`
  - `AIInsightsPanel.tsx`

- `server.js` (1449 lines) â†’ Split into route modules:
  - `routes/files.js`
  - `routes/analytics.js`
  - `routes/weather.js`

---

## 5. UNUSED CODE (P3 - CLEANUP)

### 5.1 Unused Imports

**Frontend - weather.ts:**

```typescript
// Lines 445-457: Defined but never used
export function formatTemperature(temp: number) {
  /* ... */
}
export function formatPrecipitation(precip: number) {
  /* ... */
}

// DELETE these or mark as internal utilities
```

**Frontend - holidays.ts:**

```typescript
// Line 431: Test function - remove from production
export async function testCalendarificConnection() {
  /* ... */
}
```

---

### 5.2 Unused Functions

**All unused helper functions found:**

| File          | Function                     | Line  | Action                |
| ------------- | ---------------------------- | ----- | --------------------- |
| weather.ts    | `getWeatherEmoji`            | 427   | DELETE (never called) |
| weather.ts    | `formatTemperature`          | 445   | DELETE or export      |
| weather.ts    | `formatPrecipitation`        | 452   | DELETE or export      |
| holidays.ts   | `testCalendarificConnection` | 431   | DELETE                |
| Dashboard.tsx | Mock data constants          | 22-50 | Move to separate file |

---

### 5.3 Dead Code Paths

**enrichmentService.js:**

```javascript
// Lines 186-248: Entire holiday enrichment function is dead code
// Uses Prisma which was removed - never executes successfully

// Option 1: Delete until Supabase migration complete
// Option 2: Comment out with TODO
```

---

## 6. MISSING FEATURES

### 6.1 No Test Coverage

**Critical paths without tests:**

- âŒ CSV upload and parsing
- âŒ Data enrichment pipeline
- âŒ Analytics calculations
- âŒ Authentication flow
- âŒ All API endpoints
- âŒ Frontend components

**Start with:**

```javascript
// backend/__tests__/upload.test.js
import request from 'supertest'
import app from '../server.js'

describe('File Upload', () => {
  it('should upload valid CSV file', async () => {
    const response = await request(app)
      .post('/api/files/upload')
      .attach('file', './test-data/sample.csv')
      .set('Authorization', `Bearer ${testToken}`)

    expect(response.status).toBe(200)
    expect(response.body.file.rows).toBeGreaterThan(0)
  })
})
```

---

### 6.2 Missing Input Validation

**Add Zod schemas:**

```typescript
// backend/schemas/fileUpload.js
import { z } from 'zod'

export const uploadSchema = z.object({
  file: z.object({
    size: z.number().max(50 * 1024 * 1024), // 50MB
    mimetype: z.literal('text/csv'),
  }),
})

export const analyticsSchema = z.object({
  data: z
    .array(
      z.object({
        date: z.string().datetime(),
        price: z.number().positive(),
        occupancy: z.number().min(0).max(1).optional(),
      })
    )
    .min(1)
    .max(10000),
})

// Usage in endpoint:
app.post('/api/analytics/summary', async (req, res) => {
  const validated = analyticsSchema.parse(req.body) // Throws if invalid
  // ...
})
```

---

### 6.3 No Monitoring/Logging

**Add structured logging:**

```javascript
import winston from 'winston'

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.json(),
  transports: [
    new winston.transports.File({ filename: 'error.log', level: 'error' }),
    new winston.transports.File({ filename: 'combined.log' }),
  ],
})

// Usage:
logger.info('File uploaded', {
  userId,
  fileId: property.id,
  rows: totalRows,
  processingTime: Date.now() - startTime,
})
```

---

## 7. DATABASE OPTIMIZATION

### 7.1 Missing Indexes

**Add these indexes in Supabase:**

```sql
-- Properties table
CREATE INDEX idx_properties_userid ON properties(userid);
CREATE INDEX idx_properties_status ON properties(status);
CREATE INDEX idx_properties_enrichment ON properties(enrichmentstatus);

-- Pricing data table
CREATE INDEX idx_pricing_propertyid ON pricing_data(propertyid);
CREATE INDEX idx_pricing_date ON pricing_data(date);
CREATE INDEX idx_pricing_compound ON pricing_data(propertyid, date);

-- Business settings
CREATE INDEX idx_settings_userid ON business_settings(userid);
```

---

### 7.2 N+1 Query Pattern

**File:** `backend/services/enrichmentService.js:85-105`

**Current:**

```javascript
// âŒ BAD: Loop updates (N queries for N rows)
for (const row of batch) {
  const { error } = await supabaseClient
    .from('pricing_data')
    .update({ temperature, precipitation })
    .eq('id', row.id)
}
```

**Optimized:**

```javascript
// âœ… GOOD: Bulk update (1 query for N rows)
const updateData = batch.map(row => ({
  id: row.id,
  temperature: weatherMap[row.date]?.temperature,
  precipitation: weatherMap[row.date]?.precipitation,
  // ...
}))

// Use upsert for bulk update
const { error } = await supabaseClient.from('pricing_data').upsert(updateData, {
  onConflict: 'id',
  ignoreDuplicates: false,
})
```

---

## 8. SECURITY RECOMMENDATIONS

### 8.1 Environment Variable Validation

**Add on startup:**

```javascript
// backend/config/validateEnv.js
export function validateEnvironment() {
  const required = [
    'SUPABASE_URL',
    'SUPABASE_ANON_KEY',
    'SUPABASE_SERVICE_KEY',
    'ANTHROPIC_API_KEY',
  ];

  const missing = required.filter(key => !process.env[key]);

  if (missing.length > 0) {
    console.error('âŒ Missing required environment variables:', missing);
    process.exit(1);
  }

  console.log('âœ… Environment variables validated');
}

// In server.js:
validateEnvironment();
app.listen(PORT, ...);
```

---

### 8.2 Rate Limiting (Production-Ready)

**Current limitation:**

```javascript
// âŒ In-memory rate limiting won't work across multiple servers
const rateLimitMap = new Map()
```

**Production solution:**

```javascript
import rateLimit from 'express-rate-limit'
import RedisStore from 'rate-limit-redis'
import Redis from 'ioredis'

const redis = new Redis(process.env.REDIS_URL)

const limiter = rateLimit({
  store: new RedisStore({
    client: redis,
    prefix: 'rl:',
  }),
  windowMs: 60 * 1000, // 1 minute
  max: 60, // 60 requests per minute
  message: 'Too many requests, please try again later',
})

app.use('/api/', limiter)
```

---

### 8.3 CORS Configuration

**Current:**

```javascript
// âŒ Hardcoded localhost
origin: ['http://localhost:5173', 'http://localhost:5174', process.env.FRONTEND_URL]
```

**Production:**

```javascript
// âœ… Environment-based
const allowedOrigins = process.env.ALLOWED_ORIGINS?.split(',') || []

app.use(
  cors({
    origin: (origin, callback) => {
      if (!origin || allowedOrigins.includes(origin)) {
        callback(null, true)
      } else {
        callback(new Error('CORS policy violation'))
      }
    },
    credentials: true,
  })
)
```

---

## 9. POSITIVE ASPECTS âœ…

Despite the issues, your codebase has many strengths:

### Architecture

- âœ… Clean separation: Frontend/Backend/Services
- âœ… Modern stack: React + TypeScript + Supabase
- âœ… RESTful API design
- âœ… Modular service architecture

### Features

- âœ… Comprehensive pricing analytics
- âœ… Multiple API integrations (weather, holidays, geocoding)
- âœ… Real-time enrichment pipeline
- âœ… AI-powered insights (Claude)
- âœ… Professional UI with Agrilo Grotesk theme

### Code Quality

- âœ… Consistent formatting
- âœ… Good variable naming
- âœ… Proper async/await usage
- âœ… Error messages are helpful
- âœ… Comments where needed

### User Experience

- âœ… Loading states
- âœ… Error handling UI
- âœ… Progress indicators
- âœ… Responsive design
- âœ… Authentication flow

---

## 10. ACTION PLAN

### Week 1: Critical Fixes (P0)

**Day 1-2:**

- [ ] Remove exposed API key from weather.ts
- [ ] Generate new OpenWeather API key
- [ ] Move all frontend API calls to backend proxy
- [ ] Fix function shadowing (parseFloat, parseInt)

**Day 3-4:**

- [ ] Fix/remove broken holiday enrichment
- [ ] Add error recovery for batch inserts
- [ ] Add request timeouts to all axios calls

**Day 5:**

- [ ] Test all fixes
- [ ] Deploy to staging
- [ ] Run security audit

### Week 2: High Priority (P1)

**Day 1-2:**

- [ ] Add CSV validation (structure, size, columns)
- [ ] Implement input validation with Zod
- [ ] Standardize error response format

**Day 3-4:**

- [ ] Fix React race conditions (useEffect coordination)
- [ ] Add cleanup functions for intervals/timeouts
- [ ] Implement proper error boundaries

**Day 5:**

- [ ] Add basic test coverage for critical paths
- [ ] Document API endpoints
- [ ] Code review session

### Week 3-4: Refactoring (P2)

**Week 3:**

- [ ] Extract duplicate code (date parsing, weather mapping)
- [ ] Create shared utility libraries
- [ ] Split large components (Data, Insights, server)
- [ ] Add database indexes
- [ ] Implement caching layer (React Query)

**Week 4:**

- [ ] Optimize memory usage (streaming CSV processing)
- [ ] Add monitoring/logging (Winston + Sentry)
- [ ] Migrate rate limiting to Redis
- [ ] Update CORS configuration
- [ ] Environment variable validation

### Ongoing:

- [ ] Increase test coverage to 60%+
- [ ] Performance monitoring
- [ ] Regular security audits
- [ ] Code quality metrics
- [ ] Documentation updates

---

## 11. IMMEDIATE NEXT STEPS

### Right Now (Next 2 Hours):

1. **Remove Exposed API Key**

   ```bash
   # 1. Edit frontend/src/lib/api/services/weather.ts
   # 2. Delete line 11 (hardcoded key)
   # 3. Update all functions to use backend proxy
   # 4. Generate new OpenWeather key
   # 5. Add to backend .env only
   ```

2. **Fix Function Shadowing**

   ```bash
   # Edit backend/server.js
   # Rename parseFloat â†’ parseFloatSafe (line 173)
   # Rename parseInt â†’ parseIntSafe (line 181)
   # Update all usages
   ```

3. **Add Request Timeouts**

   ```bash
   # Edit backend/server.js
   # Add timeout to all axios calls
   # Add retry logic for critical APIs
   ```

4. **Test Everything**
   ```bash
   # Test file upload
   # Test enrichment
   # Test insights generation
   # Check backend logs for errors
   ```

---

## 12. METRICS TO TRACK

### Before Fixes:

- Code Health: **6.5/10**
- Test Coverage: **0%**
- Security Score: **4/10** (exposed key)
- Performance: **6/10** (memory issues)
- Maintainability: **7/10** (good structure)

### Target After Fixes:

- Code Health: **8.5/10**
- Test Coverage: **60%+**
- Security Score: **9/10**
- Performance: **8/10**
- Maintainability: **9/10**

---

## 13. CONCLUSION

Your application is **production-ready with critical fixes**. The architecture is solid, features are comprehensive, and code quality is generally good. However, the exposed API key and missing error handling must be addressed immediately.

### Timeline to Production:

- **Week 1:** Fix P0 issues â†’ Deployable to staging
- **Week 2:** Fix P1 issues â†’ Production-ready
- **Week 3-4:** Optimizations â†’ Production-hardened
- **Ongoing:** Testing + monitoring â†’ Production-stable

### Risk Assessment:

- **High Risk:** Exposed API key, missing error recovery
- **Medium Risk:** No test coverage, memory issues
- **Low Risk:** Code duplication, missing features

### Recommendation:

**Fix P0 issues this week**, then deploy to staging. Run security audit and load testing before production deployment. The application has solid bones - it just needs critical bug fixes and production hardening.

---

**Questions or need help with specific fixes? I'm ready to implement any of these improvements immediately.**
