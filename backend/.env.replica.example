# ========================================
# Read Replica Configuration
# ========================================
# Add these environment variables to enable read replica support
# for analytics and read-heavy operations.
#
# Benefits:
#   - Offload read traffic from primary database
#   - Improved performance for analytics queries
#   - Better resource utilization
#   - Reduced latency for dashboard/reports
#
# Setup Instructions:
#   1. Create read replica in Supabase dashboard or AWS RDS
#   2. Copy these variables to your .env file
#   3. Update URLs and keys with replica credentials
#   4. Restart backend service
# ========================================

# ----------------------------------------
# Primary Database (Required)
# ----------------------------------------
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-anon-key
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# ----------------------------------------
# Read Replica (Optional)
# ----------------------------------------
# If not set, all reads will use primary database
# Set these to offload analytics/reporting to replica

SUPABASE_REPLICA_URL=https://your-replica-project.supabase.co
SUPABASE_REPLICA_ANON_KEY=your-replica-anon-key
SUPABASE_REPLICA_SERVICE_ROLE_KEY=your-replica-service-role-key

# ----------------------------------------
# Connection Pool Settings
# ----------------------------------------
DB_POOL_SIZE=10           # Number of connections in pool
DB_POOL_TIMEOUT=20000     # Connection timeout in milliseconds

# ----------------------------------------
# Replication Monitoring
# ----------------------------------------
# Set to 'true' to enable replication lag monitoring
ENABLE_REPLICATION_MONITORING=false

# Alert threshold for replication lag (seconds)
REPLICATION_LAG_THRESHOLD=5

# ========================================
# Supabase Read Replica Setup Guide
# ========================================

## Option 1: Supabase Multi-Region (Enterprise)
#
# 1. Contact Supabase support for multi-region setup
# 2. Choose replica region (e.g., us-east-1, eu-west-1)
# 3. Supabase will provision replica and provide credentials
# 4. Update SUPABASE_REPLICA_* variables above

## Option 2: AWS RDS Read Replica (Self-Hosted Supabase)
#
# 1. Create read replica in AWS RDS console:
#    - Navigate to RDS > Databases
#    - Select your primary database
#    - Actions > Create read replica
#    - Choose same or different region
#    - Configure instance size (can be smaller than primary)
#
# 2. Wait for replica to sync (check status in console)
#
# 3. Update security groups:
#    - Allow inbound traffic from your backend servers
#    - Port 5432 for PostgreSQL
#
# 4. Get replica endpoint:
#    - Copy endpoint URL from RDS console
#    - Format: your-replica.xxxx.region.rds.amazonaws.com
#
# 5. Update .env:
#    SUPABASE_REPLICA_URL=postgresql://user:password@replica-endpoint:5432/database
#
# 6. Test connection:
#    psql -h replica-endpoint -U your_user -d your_database

## Option 3: Google Cloud SQL Read Replica
#
# 1. Create read replica in Cloud SQL:
#    gcloud sql instances create replica-name \
#      --master-instance-name=primary-name \
#      --region=us-central1
#
# 2. Get connection details:
#    gcloud sql instances describe replica-name
#
# 3. Update .env with replica connection string

## Option 4: Supabase Postgres (Free Tier Workaround)
#
# Note: Free tier doesn't support read replicas.
# Instead, use connection pooling and query optimization:
#
# 1. Enable connection pooling in Supabase dashboard
# 2. Use partitioning (see partition_pricing_data.sql)
# 3. Add indexes (already done in migration)
# 4. Cache analytics results in Redis (see Task 6)

# ========================================
# Application Configuration
# ========================================

# By default, the following endpoints will use read replica (if configured):
#
# Analytics Endpoints:
#   - GET /api/analytics/demand-forecast
#   - GET /api/analytics/price-optimization
#   - GET /api/analytics/ml-performance
#   - GET /api/insights/seasonal
#   - GET /api/insights/pricing
#   - GET /api/insights/competitor
#
# Dashboard Endpoints:
#   - GET /api/dashboard/director
#   - GET /api/dashboard/statistics
#
# Reporting Endpoints:
#   - GET /api/properties/:id/statistics
#   - GET /api/properties/:id/pricing-data
#
# Write Operations (always use primary):
#   - POST /api/properties/:id/upload-csv
#   - POST /api/properties
#   - PUT /api/properties/:id
#   - DELETE /api/properties/:id

# ========================================
# Monitoring & Health Checks
# ========================================

# Health check endpoint: GET /api/health/database
# Returns:
#   {
#     "primary": true,
#     "replica": true,
#     "replicationLag": 0.123
#   }

# Prometheus metrics (if observability enabled):
#   - database_primary_connection_status
#   - database_replica_connection_status
#   - database_replication_lag_seconds

# Sentry tags:
#   - database_type: "primary" | "replica"
#   - operation_type: "read" | "write"

# ========================================
# Troubleshooting
# ========================================

## Replica not connecting
# 1. Check SUPABASE_REPLICA_URL is correct
# 2. Verify replica is running (check cloud console)
# 3. Test direct connection: psql -h replica-url ...
# 4. Check security groups/firewall rules
# 5. Verify credentials are correct

## High replication lag
# 1. Check replica instance size (may need to scale up)
# 2. Check network latency between regions
# 3. Check primary database write load
# 4. Consider reducing replica read traffic
# 5. Monitor with: SELECT * FROM pg_stat_replication;

## Queries failing on replica
# 1. Check if table exists on replica
# 2. Verify replication is active
# 3. Check for write operations sent to replica (error)
# 4. Fall back to primary: unset SUPABASE_REPLICA_URL

# ========================================
# Performance Tuning
# ========================================

# For optimal replica performance:
#
# 1. Use same instance size as primary (or larger)
# 2. Enable query caching on replica
# 3. Use connection pooling (PgBouncer)
# 4. Monitor slow queries: pg_stat_statements
# 5. Add indexes specific to analytics queries
# 6. Consider materialized views for complex reports

# Example connection pooling config (PgBouncer):
#   [databases]
#   replica = host=replica-endpoint port=5432 dbname=postgres
#
#   [pgbouncer]
#   pool_mode = transaction
#   max_client_conn = 100
#   default_pool_size = 20

# ========================================
# Cost Optimization
# ========================================

# Tips for cost-effective replica usage:
#
# 1. Use smaller instance for replica (analytics can tolerate slight slowness)
# 2. Schedule non-critical analytics during off-peak hours
# 3. Use caching (Redis) to reduce replica queries
# 4. Set up autoscaling for replica (scale down during low traffic)
# 5. Consider cross-region replica only if needed (higher cost)
# 6. Monitor replica utilization - shut down if underutilized

# Estimated costs (AWS RDS):
#   - db.t3.medium replica: ~$60/month
#   - db.t3.large replica: ~$120/month
#   - db.r5.large replica: ~$200/month
#   - Cross-region data transfer: $0.02/GB

# ========================================
# Migration Checklist
# ========================================

# Before enabling read replica:
#   □ Backup primary database
#   □ Test partition migration (partition_pricing_data.sql)
#   □ Add indexes (included in partition migration)
#   □ Provision read replica
#   □ Test replica connectivity
#   □ Update .env with replica credentials
#   □ Deploy backend code changes
#   □ Monitor replication lag
#   □ Verify analytics endpoints use replica
#   □ Check for performance improvements
#   □ Set up alerts for replica failures
#   □ Document rollback procedure

# Rollback procedure:
#   1. Unset SUPABASE_REPLICA_* env vars
#   2. Restart backend service
#   3. All traffic returns to primary
#   4. Investigate replica issues

# ========================================
